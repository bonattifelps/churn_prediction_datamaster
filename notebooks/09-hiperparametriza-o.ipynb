{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hiperparametrização\n\nEscolhemos os parametros de redução de complexidade do modelo, regularização, subamostragem e aprendizado focando em melhorar assertividade do modelo preservando o trade-off entre viés e variância, abaixo detalho os parametros:\n\n1) Redução de complexidade - profundidade das árvores, quanto mais rasa menos propensa a overfitar\n\n2) Regularização L1 para esparsidade\n\n3) Taxa de Aprendizado\n\n4) Redução de fração de amostras na contrução da arvore","metadata":{}},{"cell_type":"markdown","source":"Para realizar a troca de `RandomizedSearchCV` por uma busca bayesiana, você pode utilizar a biblioteca `BayesSearchCV` do pacote `scikit-optimize`, que é uma alternativa eficiente para otimização de hiperparâmetros. O principal benefício da busca bayesiana é que ela explora o espaço de parâmetros de forma mais inteligente, ajustando as tentativas com base nos resultados anteriores.\nAqui está o código modificado para usar a busca bayesiana, e com a métrica de recall como critério de avaliação:\n\n### Principais alterações:\n1. **Biblioteca usada:** `BayesSearchCV` do `scikit-optimize`.\n2. **Espaço de parâmetros:** A sintaxe de intervalos é ligeiramente diferente, com o uso de `(min, max)` e distribuições como `'log-uniform'`.\n3. **Critério de avaliação:** O recall foi definido como métrica principal usando `make_scorer(recall_score)` e passado para o parâmetro `scoring`.\n4. **Parâmetro `n_estimators`:** O intervalo foi ampliado para permitir uma busca mais ampla.\nEssa abordagem permitirá uma busca mais eficiente, focando em otimizar o recall.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import make_scorer, recall_score\nfrom skopt import BayesSearchCV\nfrom xgboost import XGBClassifier\n\n# Definir o modelo inicial\nmodel = XGBClassifier(scale_pos_weight=scale_pos_weight, use_label_encoder=False)\n\n# Parâmetros para Busca Bayesiana (extremamente simplificados)\nparam_dist = {\n    'max_depth': (1, 2),  # Profundidade mínima\n    'reg_alpha': (0.01, 0.1),  # Regularização leve\n    'learning_rate': (0.01, 0.1),  # Taxa de aprendizado baixa\n    'n_estimators': (5, 10),  # Valor muito baixo para árvores\n    'subsample': (0.5, 1.0),  # Usar entre 50% a 100% dos dados\n    'colsample_bytree': (0.5, 1.0)  # Usar entre 50% a 100% das colunas\n}\n\n# Scorer baseado em recall\nrecall = make_scorer(recall_score)\n\n# Amostragem do conjunto de dados (1% dos dados)\nX_train_sample = X_train.sample(frac=0.01, random_state=42)  # Usar 1% dos dados\ny_train_sample = y_train.loc[X_train_sample.index]\n\n# BayesSearchCV com validação cruzada (configurado para ser extremamente rápido)\nbayes_search = BayesSearchCV(\n    estimator=model,\n    search_spaces=param_dist,\n    n_iter=1,  # Apenas uma iteração\n    cv=2,  # Validação cruzada com 2 folds\n    n_jobs=1,  # Usar apenas um núcleo para evitar sobrecarga\n    verbose=0,  # Silenciar logs\n    random_state=3,\n    scoring=recall\n)\n\n# Aplicando a busca (sem avaliação)\nbayes_search.fit(X_train_sample, y_train_sample)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Melhor modelo e parâmetros\nbest_model_bayes = bayes_search.best_estimator_\nprint(f\"Best parameters (BayesSearchCV): {bayes_search.best_params_}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Best score (BayesSearchCV - Recall): {bayes_search.best_score_}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Avaliação do modelo final\ny_pred_bayes = best_model_bayes.predict(X_test)\ny_pred_proba_bayes = best_model_bayes.predict_proba(X_test)[:, 1]\n\n# Métricas\naccuracy_bayes = recall_score(y_test, y_pred_bayes)\nauc_bayes = roc_auc_score(y_test, y_pred_proba_bayes)\nf1_bayes = f1_score(y_test, y_pred_bayes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Test recall (BayesSearchCV): {accuracy_bayes}\")\nprint(f\"Test AUC (BayesSearchCV): {auc_bayes}\")\nprint(f\"Test F1 Score (BayesSearchCV): {f1_bayes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
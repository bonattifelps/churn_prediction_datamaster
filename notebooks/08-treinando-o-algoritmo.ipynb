{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Treinando o algoritmo\n\nPara o treinamento optamos por testar diferentes classes, cujos principais pontos positivos e negativos estão descritos abaixo:\n\n\n### 1. **LightGBM**\n  - **Por que usar:**  Muito rápido e eficiente em termos de uso de memória, especialmente em conjuntos de dados grandes, permite ajuste fino de muitos parâmetros, como a profundidade da árvore e o número de folhas, para melhorar o desempenho e lida bem com conjuntos de dados esparsos, o que é comum em problemas com muitas variáveis categóricas.\n  - **Por que não usar LightGBM:** tem muitoshiperparâmetros que precisam ser ajustados corretamente, o que pode ser complexo e demorado e como outros algoritmos de gradient boosting, pode ser suscetível a overfitting, especialmente em conjuntos de dados pequenos ou mal balanceados.\n\n### 2. **XGBoost (XGBClassifier)**\n  - **Por que usar:** É  uma técnica de boosting extremamente eficiente e poderosa que geralmente supera muitos outros algoritmos em termos de performance em problemas de classificação. Ele é bom em capturar interações complexas e pode lidar com dados desbalanceados, que são comuns em problemas de churn.\n  - **Por que não usar:** Similar ao Random Forest, XGBoost pode ser caro em termos computacionais. Além disso, requer um ajuste de hiperparâmetros mais cuidadoso para evitar overfitting, o que pode aumentar o tempo de desenvolvimento.\n\n### 3. **Random Forest**\n  - **Por que usar:** Robustex cobtra Overfiting, lida bem com dados faltantes\n  - **Por que não usar:** Propensas a Bias","metadata":{}},{"cell_type":"markdown","source":"Aqui está um código que implementa os ajustes para `scale_pos_weight`, `sample_weight`, e o ajuste do threshold de decisão no XGBoost para lidar com dados desbalanceados:\n### Explicação:\n1. **Ajuste do `scale_pos_weight`** (ponto 2): Calculamos a razão entre as amostras negativas e positivas no conjunto de treino para balancear o impacto das classes.\n2. **Uso de `sample_weight`** (ponto 4): Aplicamos pesos diferentes às amostras, dando mais importância às da classe minoritária.\n3. **Threshold tuning** (ponto 5): Ao invés de usar o threshold padrão de 0.5 para a probabilidade de previsão, ajustamos para 0.3 para captar mais positivos.\nEsse código pode ser adaptado ao seu problema específico, ajustando os parâmetros conforme necessário.","metadata":{}},{"cell_type":"code","source":"# Calculando scale_pos_weight\nnum_pos = np.sum(y_train == 1)  # Número de positivos\nnum_neg = np.sum(y_train == 0)  # Número de negativos\nscale_pos_weight = num_neg / num_pos","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model  import LogisticRegression\n# Application of all Machine Learning methods\nMLA = [\n    LogisticRegression(class_weight='balanced',C=1),\n\n    # LightGBM\n    LGBMClassifier(scale_pos_weight=scale_pos_weight,  # Ajuste para classes desbalanceadas\n   use_label_encoder=True),\n\n    #Ensemble Methods\n    XGBClassifier( scale_pos_weight=scale_pos_weight,  # Ajuste para classes desbalanceadas\n   use_label_encoder=True),\n\n    #Random Forest\n    RandomForestClassifier(max_depth=2,class_weight = 'balanced')\n\n    ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import precision_score, recall_score, roc_curve, auc, f1_score\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn import linear_model, ensemble, tree, naive_bayes\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nimport numpy as np\n\n\n# Inicializando as colunas do DataFrame para comparação\nMLA_columns = ['MLA used', 'Train Accuracy', 'Validation Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\nMLA_compare = pd.DataFrame(columns=MLA_columns)\n\n# Índice para linhas do DataFrame\nrow_index = 0\n\n# Loop para cada algoritmo na lista MLA\nfor alg in MLA:\n    print(f\"Evaluando {alg.__class__.__name__}...\")\n\n    # Validação Cruzada usando o conjunto de treinamento\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    val_accuracies = []\n    val_precisions = []\n    val_recalls = []\n    val_f1_scores = []\n    val_auc_scores = []\n\n    for train_index, val_index in kf.split(X_train):\n        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n        # Treinando o modelo\n        alg.fit(X_train_fold, y_train_fold)\n\n        # Predições e métricas no conjunto de validação\n        y_val_pred = alg.predict(X_val_fold)\n        y_val_pred_proba = alg.predict_proba(X_val_fold)[:, 1] if hasattr(alg, 'predict_proba') else y_val_pred\n\n        val_accuracies.append(alg.score(X_val_fold, y_val_fold))\n        val_precisions.append(precision_score(y_val_fold, y_val_pred))\n        val_recalls.append(recall_score(y_val_fold, y_val_pred))\n        val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n        fp, tp, _ = roc_curve(y_val_fold, y_val_pred_proba)\n        val_auc_scores.append(auc(fp, tp))\n\n    # Calculando métricas médias\n    val_accuracy = round(np.mean(val_accuracies), 4)\n    val_precision = round(np.mean(val_precisions), 4)\n    val_recall = round(np.mean(val_recalls), 4)\n    val_f1 = round(np.mean(val_f1_scores), 4)\n    val_auc = round(np.mean(val_auc_scores), 4)\n\n    # Treinamento final no conjunto de treino\n    alg.fit(X_train, y_train)\n\n    # Avaliação final no conjunto de teste\n    y_test_pred = alg.predict(X_test)\n    y_test_pred_proba = alg.predict_proba(X_test)[:, 1] if hasattr(alg, 'predict_proba') else y_test_pred\n\n    test_accuracy = round(alg.score(X_test, y_test), 4)\n    precision = precision_score(y_test, y_test_pred)\n    recall = recall_score(y_test, y_test_pred)\n    f1 = f1_score(y_test, y_test_pred)\n    fp, tp, _ = roc_curve(y_test, y_test_pred_proba)\n    auc_score = auc(fp, tp)\n\n    # Armazenando métricas no DataFrame\n    MLA_compare.loc[row_index] = [alg.__class__.__name__,\n                                   round(alg.score(X_train, y_train), 4),\n                                   val_accuracy,\n                                   test_accuracy,\n                                   precision,\n                                   recall,\n                                   f1,\n                                   auc_score]\n\n    row_index += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MLA_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)\nMLA_compare","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prevendo 3 meses a frente\nPor fim iremos finalizar a previsão dos clientes que nao deram churn neste mês mas que poderiam dar no proximo ou em M2, M3 com os valores otimos da busca bayesiana. \n\nCriaremos também uma função de visualização para os resultados do modelo.","metadata":{}},{"cell_type":"code","source":"join_tables['safra'] = pd.to_datetime(join_tables.safra, format='%Y%m', errors='coerce').dt.strftime('%Y%m')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Notebook 4\njoin_tables['churn_1'] = join_tables.groupby('msno')['is_churn'].shift(-1)\njoin_tables['churn_2'] = join_tables.groupby('msno')['is_churn'].shift(-2)\njoin_tables['churn_3'] = join_tables.groupby('msno')['is_churn'].shift(-3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Previsão para M1\nx1m = join_tables.dropna(subset=['churn_1']).filter(feature_importance_df)\ny_1m = join_tables.dropna(subset=['churn_1'])['churn_1']\n\n# Previsão para M2\nx2m = join_tables.dropna(subset=['churn_2']).filter(feature_importance_df)\ny_2m = join_tables.dropna(subset=['churn_2'])['churn_2']\n\n# Previsão para M3\nx3m = join_tables.dropna(subset=['churn_3']).filter(feature_importance_df)\ny_3m = join_tables.dropna(subset=['churn_3'])['churn_3']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_tables.sort_values(by=['msno', 'safra'], ascending = False, inplace = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Treinamento e teste para previsão de 1 mês (M1)\nX_train1, X_test1m, y_train_1m, y_test_1m = train_test_split(x1m, y_1m, test_size=0.3, random_state=42)\ncostumer_churn_prediction(xgc, X_train1, X_test1m, y_train_1m, y_test_1m, \"features\", threshold_plot=True)\n\n# Treinamento e teste para previsão de 2 meses (M2)\nX_train2, X_test2m, y_train_2m, y_test_2m = train_test_split(x2m, y_2m, test_size=0.3, random_state=42)\ncostumer_churn_prediction(xgc, X_train2, X_test2m, y_train_2m, y_test_2m, \"features\", threshold_plot=True)\n\n# Treinamento e teste para previsão de 3 meses (M3)\nX_train3, X_test3m, y_train_3m, y_test_3m = train_test_split(x3m, y_3m, test_size=0.3, random_state=42)\ncostumer_churn_prediction(xgc, X_train3, X_test3m, y_train_3m, y_test_3m, \"features\", threshold_plot=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Previsão e cálculo do churn em cada janela\nfor period, y_pred, y_test in zip(['1 mês', '2 meses', '3 meses'], \n                                  [y_pred_1m, y_pred_2m, y_pred_3m], \n                                  [y_test_1m, y_test_2m, y_test_3m]):\n    total_churn = (y_pred == 1).sum()\n    print(f'Percentual de clientes com churn em {period}: {total_churn / len(y_pred):.2%}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom math import * # module math\nimport matplotlib.pyplot as plt # visualization\nfrom PIL import Image\nimport seaborn as sns # visualization\nimport itertools\nimport io\nimport plotly.offline as py # visualization\npy.init_notebook_mode(connected=True) # visualization\nimport plotly.graph_objs as go # visualization\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff # visualization\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport statsmodels.api as sm\nfrom yellowbrick.classifier import DiscriminationThreshold\n\n%matplotlib inline","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def costumer_churn_prediction(algorithm, training_x, testing_x, training_y, testing_y, cf, threshold_plot):\n    #model\n    algorithm.fit(training_x, training_y)\n    predictions = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n        \n    print('Algorithm:', type(algorithm).__name__)\n    print(\"\\nClassification report:\\n\", classification_report(testing_y, predictions))\n    print(\"Accuracy Score:\", accuracy_score(testing_y, predictions))\n    \n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y, predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y, predictions) \n    print(\"Area under curve:\", model_roc_auc,\"\\n\")\n    \n    fpr, tpr, thresholds = roc_curve(testing_y, probabilities[:,1])\n     \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix,\n                        x = [\"Not churn\", \"Churn\"],\n                        y = [\"Not churn\", \"Churn\"],\n                        showscale = False, colorscale = \"Picnic\",\n                        name = \"Confusion matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr, y = tpr,\n                        name = \"Roc: \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'), width = 2))\n    trace3 = go.Scatter(x = [0,1], y = [0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'), width = 2,\n                        dash = 'dot'))\n    \n    if cf in ['coefficients', 'features']:\n        if cf == 'coefficients':\n            coefficients = pd.DataFrame(algorithm.coef_.ravel())\n        elif cf == 'features':\n            coefficients = pd.DataFrame(algorithm.feature_importances_)\n        \n        column_df = pd.DataFrame(training_x.columns.tolist())\n        coef_sumry = (pd.merge(coefficients, column_df, left_index=True, \n                               right_index=True, how=\"left\"))\n        coef_sumry.columns = [\"coefficients\", \"features\"]\n        coef_sumry = coef_sumry.sort_values(by = \"coefficients\", ascending=False)\n        \n        #plot coeffs\n        trace4 = go.Bar(x = coef_sumry[\"features\"], y = coef_sumry[\"coefficients\"], \n                        name = \"coefficients\",\n                        marker = dict(color = coef_sumry[\"coefficients\"],\n                                      colorscale = \"Picnic\",\n                                      line = dict(width = .6, color = \"black\")\n                                     )\n                       )\n        #subplots\n        fig = make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                                subplot_titles=('Confusion matrix',\n                                                'Receiver operating characteristic',\n                                                'Feature importances')\n                           )  \n        fig.append_trace(trace1,1,1)\n        fig.append_trace(trace2,1,2)\n        fig.append_trace(trace3,1,2)\n        fig.append_trace(trace4,2,1)\n        fig['layout'].update(showlegend=False, title=\"Model performance\",\n                             autosize=False, height = 900, width = 800,\n                             plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                             paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                             margin = dict(b = 195))\n        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n        fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True, tickfont = dict(size = 10), tickangle = 90))\n        \n    elif cf == 'None':\n        #subplots\n        fig = make_subplots(rows=1, cols=2,\n                            subplot_titles=('Confusion matrix',\n                                            'Receiver operating characteristic')\n                           )\n        fig.append_trace(trace1,1,1)\n        fig.append_trace(trace2,1,2)\n        fig.append_trace(trace3,1,2)\n        fig['layout'].update(showlegend=False, title=\"Model performance\",\n                         autosize=False, height = 500, width = 800,\n                         plot_bgcolor = 'rgba(240,240,240,0.95)',\n                         paper_bgcolor = 'rgba(240,240,240,0.95)',\n                         margin = dict(b = 195))\n        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))  \n        \n    py.iplot(fig)\n    \n    if threshold_plot == True: \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separar variáveis explicativas e alvo para previsão de churn no próximo mês\n\n# Dividir os dados em conjuntos de treinamento e teste\nX_train1, X_test1m, y_train_1m, y_test_1m = train_test_split(x1m, y_1m, test_size=0.3, random_state=42)\n\n\nfrom xgboost import XGBClassifier\n\nxgc = XGBClassifier(scale_pos_weight=scale_pos_weight,  # Ajuste para classes desbalanceadas\n   use_label_encoder=False, reg_lambda =  0.1, reg_alpha = 0.644, n_estimators = 50,\n                         max_depth = 2, learning_rate = 0.11)\n\ncostumer_churn_prediction(xgc, X_train1, X_test1m, y_train_1m, y_test_1m, \"features\", threshold_plot=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Percentual de clientes com churn:',(total_churn_1m)/(len(y_pred_1m)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Conclusão:**\nConseguimos identificar 6% clientes com possível  churn nos proximos três meses.\nEntendendo que X% ficam ativos pós ação, conseguiremos reter X%.\n\nÉ importante passar a lista destes clientes para que a area de negocio entre em contato tentando fortalecer e restabelecer o relacionamento com o objetivo de reduzir o provável churn.\n\nPara finalizar, iremos realizar a analise não supervisionada, agrupar nossos clientes e tentar buscar padrões de churn e comportamento.","metadata":{}}]}